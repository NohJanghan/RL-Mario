{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uv 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<url>https://sigridjin.medium.com/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%9D%BC%EB%A9%B4-uv-%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%A9%EC%8B%9C%EB%8B%A4-546d523f7178<url>\n",
    "<br>\n",
    "<url>https://rudaks.tistory.com/entry/python%EC%9D%98-uv-%EC%82%AC%EC%9A%A9%EB%B2%95<url>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# terminal 에서\n",
    "brew install uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# project 생성 : 폴더 생성하니 프로젝트를 만들고 싶은 위치에서 실행\n",
    "uv init <project_name> \n",
    "# 설치가 되면 디렉토리 이동\n",
    "cd <project_name>\n",
    "\n",
    "# venv 생성\n",
    "uv venv <venv_name>\n",
    "# venv 실행\n",
    "source ./venv/<venv_name>/bin/activate\n",
    "# 파이썬 설치\n",
    "uv python install 3.10 or later\n",
    "# 주의!!! ipynb 사용 시에는 반드시 --devfh ipykernel 설치 할 것. 파이썬 버전은 이 라이브러리 버전으로 잡히니, notebook에서 버전 확인이 이상하면 이 패키지 관리\n",
    "uv add --dev ipykernel\n",
    "# 나머지 필요 패키지 설치\n",
    "uv add torch torchvision torchaudio gym-super-mario-bros numpy=1.22.4 pandas matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code\n",
    "%%bash\n",
    "uv add gym-super-mario-bros==7.4.0\n",
    "uv add tensordict==0.3.0\n",
    "uv add torchrl==0.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<url>https://tutorials.pytorch.kr/intermediate/mario_rl_tutorial.html#<url>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import random, datetime, os\n",
    "\n",
    "# Gym은 강화학습을 위한 OpenAI 툴킷입니다.\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "from gym.wrappers import FrameStack\n",
    "\n",
    "# OpenAI Gym을 위한 NES 에뮬레이터\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "# OpenAI Gym에서의 슈퍼 마리오 환경 세팅\n",
    "import gym_super_mario_bros\n",
    "\n",
    "from tensordict import TensorDict\n",
    "from torchrl.data import TensorDictReplayBuffer, LazyMemmapStorage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error uint8~~~\n",
    "<url>https://stackoverflow.com/questions/78757000/overflowerror-when-setting-up-gym-super-mario-bros-environment-in-python-on-jupy<url>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL-env setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bagjuhyeon/RL-game/.venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/bagjuhyeon/RL-game/.venv/lib/python3.10/site-packages/gym/envs/registration.py:627: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'video.frames_per_second']\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 256, 3),\n",
      " 0.0,\n",
      " False,\n",
      " {'coins': 0, 'flag_get': False, 'life': 2, 'score': 0, 'stage': 1, 'status': 'small', 'time': 400, 'world': 1, 'x_pos': 40, 'y_pos': 79}\n"
     ]
    }
   ],
   "source": [
    "# 슈퍼 마리오 환경 초기화하기 (in v0.26 change render mode to 'human' to see results on the screen)\n",
    "# numpy 2.0 version은 uint8에서 crash\n",
    "if gym.__version__ < '0.26':\n",
    "    env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\", new_step_api=True)\n",
    "else:\n",
    "    env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\", render_mode='human', apply_api_compatibility=True)\n",
    "\n",
    "# 상태 공간을 2가지로 제한하기\n",
    "#   0. 오른쪽으로 걷기\n",
    "#   1. 오른쪽으로 점프하기\n",
    "env = JoypadSpace(env, [[\"right\"], [\"right\", \"A\"]])\n",
    "\n",
    "env.reset()\n",
    "next_state, reward, done, trunc, info = env.step(action=0)\n",
    "print(f\"{next_state.shape},\\n {reward},\\n {done},\\n {info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipFrame(gym.Wrapper):\n",
    "    def __init__(self, env, skip):\n",
    "        \"\"\"모든 `skip` 프레임만 반환합니다.\"\"\"\n",
    "        super().__init__(env)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"행동을 반복하고 포상을 더합니다.\"\"\"\n",
    "        total_reward = 0.0\n",
    "        for i in range(self._skip):\n",
    "            # 포상을 누적하고 동일한 작업을 반복합니다.\n",
    "            obs, reward, done, trunk, info = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, done, trunk, info\n",
    "\n",
    "\n",
    "class GrayScaleObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        obs_shape = self.observation_space.shape[:2]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def permute_orientation(self, observation):\n",
    "        # [H, W, C] 배열을 [C, H, W] 텐서로 바꿉니다.\n",
    "        observation = np.transpose(observation, (2, 0, 1))\n",
    "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
    "        return observation\n",
    "\n",
    "    def observation(self, observation):\n",
    "        observation = self.permute_orientation(observation)\n",
    "        transform = T.Grayscale()\n",
    "        observation = transform(observation)\n",
    "        return observation\n",
    "\n",
    "\n",
    "class ResizeObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env, shape):\n",
    "        super().__init__(env)\n",
    "        if isinstance(shape, int):\n",
    "            self.shape = (shape, shape)\n",
    "        else:\n",
    "            self.shape = tuple(shape)\n",
    "\n",
    "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        transforms = T.Compose(\n",
    "            [T.Resize(self.shape, antialias=True), T.Normalize(0, 255)]\n",
    "        )\n",
    "        observation = transforms(observation).squeeze(0)\n",
    "        return observation\n",
    "\n",
    "\n",
    "# 래퍼를 환경에 적용합니다.\n",
    "env = SkipFrame(env, skip=4)\n",
    "env = GrayScaleObservation(env)\n",
    "env = ResizeObservation(env, shape=84)\n",
    "if gym.__version__ < '0.26':\n",
    "    env = FrameStack(env, num_stack=4, new_step_api=True)\n",
    "else:\n",
    "    env = FrameStack(env, num_stack=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Env - Mario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario:\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # 마리오의 DNN은 최적의 행동을 예측합니다 - 이는 학습하기 섹션에서 구현합니다.\n",
    "        self.net = MarioNet(self.state_dim, self.action_dim).float()\n",
    "        self.net = self.net.to(device=self.device)\n",
    "\n",
    "        self.exploration_rate = 1\n",
    "        self.exploration_rate_decay = 0.99999975\n",
    "        self.exploration_rate_min = 0.1\n",
    "        self.curr_step = 0\n",
    "\n",
    "        self.save_every = 5e5  # Mario Net 저장 사이의 경험 횟수\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"\n",
    "    주어진 상태에서, 입실론-그리디 행동(epsilon-greedy action)을 선택하고, 스텝의 값을 업데이트 합니다.\n",
    "\n",
    "    입력값:\n",
    "    state (``LazyFrame``): 현재 상태에서의 단일 상태(observation)값을 말합니다. 차원은 (state_dim)입니다.\n",
    "    출력값:\n",
    "    ``action_idx`` (int): Mario가 수행할 행동을 나타내는 정수 값입니다.\n",
    "    \"\"\"\n",
    "        # 임의의 행동을 선택하기\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            action_idx = np.random.randint(self.action_dim)\n",
    "\n",
    "        # 최적의 행동을 이용하기\n",
    "        else:\n",
    "            state = state[0].__array__() if isinstance(state, tuple) else state.__array__()\n",
    "            state = torch.tensor(state, device=self.device).unsqueeze(0)\n",
    "            action_values = self.net(state, model=\"online\")\n",
    "            action_idx = torch.argmax(action_values, axis=1).item()\n",
    "\n",
    "        # exploration_rate 감소하기\n",
    "        self.exploration_rate *= self.exploration_rate_decay\n",
    "        self.exploration_rate = max(self.exploration_rate_min, self.exploration_rate)\n",
    "\n",
    "        # 스텝 수 증가하기\n",
    "        self.curr_step += 1\n",
    "        return action_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):  # 연속성을 위한 하위 클래스입니다.\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.memory = TensorDictReplayBuffer(storage=LazyMemmapStorage(100000, device=torch.device(\"cpu\")))\n",
    "        self.batch_size = 32\n",
    "\n",
    "    def cache(self, state, next_state, action, reward, done):\n",
    "        \"\"\"\n",
    "        Store the experience to self.memory (replay buffer)\n",
    "\n",
    "        입력값:\n",
    "        state (``LazyFrame``),\n",
    "        next_state (``LazyFrame``),\n",
    "        action (``int``),\n",
    "        reward (``float``),\n",
    "        done(``bool``))\n",
    "        \"\"\"\n",
    "        def first_if_tuple(x):\n",
    "            return x[0] if isinstance(x, tuple) else x\n",
    "        state = first_if_tuple(state).__array__()\n",
    "        next_state = first_if_tuple(next_state).__array__()\n",
    "\n",
    "        state = torch.tensor(state)\n",
    "        next_state = torch.tensor(next_state)\n",
    "        action = torch.tensor([action])\n",
    "        reward = torch.tensor([reward])\n",
    "        done = torch.tensor([done])\n",
    "\n",
    "        # self.memory.append((state, next_state, action, reward, done,))\n",
    "        self.memory.add(TensorDict({\"state\": state, \"next_state\": next_state, \"action\": action, \"reward\": reward, \"done\": done}, batch_size=[]))\n",
    "\n",
    "    def recall(self):\n",
    "        \"\"\"\n",
    "        메모리에서 일련의 경험들을 검색합니다.\n",
    "        \"\"\"\n",
    "        batch = self.memory.sample(self.batch_size).to(self.device)\n",
    "        state, next_state, action, reward, done = (batch.get(key) for key in (\"state\", \"next_state\", \"action\", \"reward\", \"done\"))\n",
    "        return state, next_state, action.squeeze(), reward.squeeze(), done.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MarioNet(CNN model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.gamma = 0.9\n",
    "\n",
    "    def td_estimate(self, state, action):\n",
    "        current_Q = self.net(state, model=\"online\")[\n",
    "            np.arange(0, self.batch_size), action\n",
    "        ]  # Q_online(s,a)\n",
    "        return current_Q\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def td_target(self, reward, next_state, done):\n",
    "        next_state_Q = self.net(next_state, model=\"online\")\n",
    "        best_action = torch.argmax(next_state_Q, axis=1)\n",
    "        next_Q = self.net(next_state, model=\"target\")[\n",
    "            np.arange(0, self.batch_size), best_action\n",
    "        ]\n",
    "        return (reward + (1 - done.float()) * self.gamma * next_Q).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=0.00025)\n",
    "        self.loss_fn = torch.nn.SmoothL1Loss()\n",
    "\n",
    "    def update_Q_online(self, td_estimate, td_target):\n",
    "        loss = self.loss_fn(td_estimate, td_target)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def sync_Q_target(self):\n",
    "        self.net.target.load_state_dict(self.net.online.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def save(self):\n",
    "        save_path = (\n",
    "            self.save_dir / f\"mario_net_{int(self.curr_step // self.save_every)}.chkpt\"\n",
    "        )\n",
    "        torch.save(\n",
    "            dict(model=self.net.state_dict(), exploration_rate=self.exploration_rate),\n",
    "            save_path,\n",
    "        )\n",
    "        print(f\"MarioNet saved to {save_path} at step {self.curr_step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.burnin = 1e4  # 학습을 진행하기 전 최소한의 경험값.\n",
    "        self.learn_every = 3  # Q_online 업데이트 사이의 경험 횟수.\n",
    "        self.sync_every = 1e4  # Q_target과 Q_online sync 사이의 경험 수\n",
    "\n",
    "    def learn(self):\n",
    "        if self.curr_step % self.sync_every == 0:\n",
    "            self.sync_Q_target()\n",
    "\n",
    "        if self.curr_step % self.save_every == 0:\n",
    "            self.save()\n",
    "\n",
    "        if self.curr_step < self.burnin:\n",
    "            return None, None\n",
    "\n",
    "        if self.curr_step % self.learn_every != 0:\n",
    "            return None, None\n",
    "\n",
    "        # 메모리로부터 샘플링을 합니다.\n",
    "        state, next_state, action, reward, done = self.recall()\n",
    "\n",
    "        # TD 추정값을 가져옵니다.\n",
    "        td_est = self.td_estimate(state, action)\n",
    "\n",
    "        # TD 목표값을 가져옵니다.\n",
    "        td_tgt = self.td_target(reward, next_state, done)\n",
    "\n",
    "        # 실시간 Q(Q_online)을 통해 역전파 손실을 계산합니다.\n",
    "        loss = self.update_Q_online(td_est, td_tgt)\n",
    "\n",
    "        return (td_est.mean().item(), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logger -> perception of agent behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MetricLogger:\n",
    "    def __init__(self, save_dir):\n",
    "        self.save_log = save_dir / \"log\"\n",
    "        with open(self.save_log, \"w\") as f:\n",
    "            f.write(\n",
    "                f\"{'Episode':>8}{'Step':>8}{'Epsilon':>10}{'MeanReward':>15}\"\n",
    "                f\"{'MeanLength':>15}{'MeanLoss':>15}{'MeanQValue':>15}\"\n",
    "                f\"{'TimeDelta':>15}{'Time':>20}\\n\"\n",
    "            )\n",
    "        self.ep_rewards_plot = save_dir / \"reward_plot.jpg\"\n",
    "        self.ep_lengths_plot = save_dir / \"length_plot.jpg\"\n",
    "        self.ep_avg_losses_plot = save_dir / \"loss_plot.jpg\"\n",
    "        self.ep_avg_qs_plot = save_dir / \"q_plot.jpg\"\n",
    "\n",
    "        # 지표(Metric)와 관련된 리스트입니다.\n",
    "        self.ep_rewards = []\n",
    "        self.ep_lengths = []\n",
    "        self.ep_avg_losses = []\n",
    "        self.ep_avg_qs = []\n",
    "\n",
    "        # 모든 record() 함수를 호출한 후 이동 평균(Moving average)을 계산합니다.\n",
    "        self.moving_avg_ep_rewards = []\n",
    "        self.moving_avg_ep_lengths = []\n",
    "        self.moving_avg_ep_avg_losses = []\n",
    "        self.moving_avg_ep_avg_qs = []\n",
    "\n",
    "        # 현재 에피스드에 대한 지표를 기록합니다.\n",
    "        self.init_episode()\n",
    "\n",
    "        # 시간에 대한 기록입니다.\n",
    "        self.record_time = time.time()\n",
    "\n",
    "    def log_step(self, reward, loss, q):\n",
    "        self.curr_ep_reward += reward\n",
    "        self.curr_ep_length += 1\n",
    "        if loss:\n",
    "            self.curr_ep_loss += loss\n",
    "            self.curr_ep_q += q\n",
    "            self.curr_ep_loss_length += 1\n",
    "\n",
    "    def log_episode(self):\n",
    "        \"에피스드의 끝을 표시합니다.\"\n",
    "        self.ep_rewards.append(self.curr_ep_reward)\n",
    "        self.ep_lengths.append(self.curr_ep_length)\n",
    "        if self.curr_ep_loss_length == 0:\n",
    "            ep_avg_loss = 0\n",
    "            ep_avg_q = 0\n",
    "        else:\n",
    "            ep_avg_loss = np.round(self.curr_ep_loss / self.curr_ep_loss_length, 5)\n",
    "            ep_avg_q = np.round(self.curr_ep_q / self.curr_ep_loss_length, 5)\n",
    "        self.ep_avg_losses.append(ep_avg_loss)\n",
    "        self.ep_avg_qs.append(ep_avg_q)\n",
    "\n",
    "        self.init_episode()\n",
    "\n",
    "    def init_episode(self):\n",
    "        self.curr_ep_reward = 0.0\n",
    "        self.curr_ep_length = 0\n",
    "        self.curr_ep_loss = 0.0\n",
    "        self.curr_ep_q = 0.0\n",
    "        self.curr_ep_loss_length = 0\n",
    "\n",
    "    def record(self, episode, epsilon, step):\n",
    "        mean_ep_reward = np.round(np.mean(self.ep_rewards[-100:]), 3)\n",
    "        mean_ep_length = np.round(np.mean(self.ep_lengths[-100:]), 3)\n",
    "        mean_ep_loss = np.round(np.mean(self.ep_avg_losses[-100:]), 3)\n",
    "        mean_ep_q = np.round(np.mean(self.ep_avg_qs[-100:]), 3)\n",
    "        self.moving_avg_ep_rewards.append(mean_ep_reward)\n",
    "        self.moving_avg_ep_lengths.append(mean_ep_length)\n",
    "        self.moving_avg_ep_avg_losses.append(mean_ep_loss)\n",
    "        self.moving_avg_ep_avg_qs.append(mean_ep_q)\n",
    "\n",
    "        last_record_time = self.record_time\n",
    "        self.record_time = time.time()\n",
    "        time_since_last_record = np.round(self.record_time - last_record_time, 3)\n",
    "\n",
    "        print(\n",
    "            f\"Episode {episode} - \"\n",
    "            f\"Step {step} - \"\n",
    "            f\"Epsilon {epsilon} - \"\n",
    "            f\"Mean Reward {mean_ep_reward} - \"\n",
    "            f\"Mean Length {mean_ep_length} - \"\n",
    "            f\"Mean Loss {mean_ep_loss} - \"\n",
    "            f\"Mean Q Value {mean_ep_q} - \"\n",
    "            f\"Time Delta {time_since_last_record} - \"\n",
    "            f\"Time {datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\"\n",
    "        )\n",
    "\n",
    "        with open(self.save_log, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"{episode:8d}{step:8d}{epsilon:10.3f}\"\n",
    "                f\"{mean_ep_reward:15.3f}{mean_ep_length:15.3f}{mean_ep_loss:15.3f}{mean_ep_q:15.3f}\"\n",
    "                f\"{time_since_last_record:15.3f}\"\n",
    "                f\"{datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S'):>20}\\n\"\n",
    "            )\n",
    "\n",
    "        for metric in [\"ep_lengths\", \"ep_avg_losses\", \"ep_avg_qs\", \"ep_rewards\"]:\n",
    "            plt.clf()\n",
    "            plt.plot(getattr(self, f\"moving_avg_{metric}\"), label=f\"moving_avg_{metric}\")\n",
    "            plt.legend()\n",
    "            plt.savefig(getattr(self, f\"{metric}_plot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mps.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n",
      "Using MPS: True\n",
      "Episode 0 - Step 40 - Epsilon 0.9999900000487484 - Mean Reward 231.0 - Mean Length 40.0 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 0.54 - Time 2025-05-07T19:46:28\n",
      "Episode 20 - Step 5339 - Epsilon 0.9986661402157843 - Mean Reward 725.143 - Mean Length 254.238 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 63.388 - Time 2025-05-07T19:47:31\n",
      "Episode 39 - Step 8615 - Epsilon 0.9978485673864063 - Mean Reward 687.3 - Mean Length 215.375 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 38.553 - Time 2025-05-07T19:48:10\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "print(f\"Using CUDA: {use_cuda}\")\n",
    "print(f\"Using MPS: {use_mps}\")\n",
    "\n",
    "save_dir = Path(\"checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "save_dir.mkdir(parents=True)\n",
    "\n",
    "mario = Mario(state_dim=(4, 84, 84), action_dim=env.action_space.n, save_dir=save_dir)\n",
    "\n",
    "logger = MetricLogger(save_dir)\n",
    "\n",
    "episodes = 40\n",
    "for e in range(episodes):\n",
    "\n",
    "    state = env.reset()\n",
    "\n",
    "    # 게임을 실행시켜봅시다!\n",
    "    while True:\n",
    "\n",
    "        # 현재 상태에서 에이전트 실행하기\n",
    "        action = mario.act(state)\n",
    "\n",
    "        # 에이전트가 액션 수행하기\n",
    "        next_state, reward, done, trunc, info = env.step(action)\n",
    "\n",
    "        # 기억하기\n",
    "        mario.cache(state, next_state, action, reward, done)\n",
    "\n",
    "        # 배우기\n",
    "        q, loss = mario.learn()\n",
    "\n",
    "        # 기록하기\n",
    "        logger.log_step(reward, loss, q)\n",
    "\n",
    "        # 상태 업데이트하기\n",
    "        state = next_state\n",
    "\n",
    "        # 게임이 끝났는지 확인하기\n",
    "        if done or info[\"flag_get\"]:\n",
    "            break\n",
    "\n",
    "    logger.log_episode()\n",
    "\n",
    "    if (e % 20 == 0) or (e == episodes - 1):\n",
    "        logger.record(episode=e, epsilon=mario.exploration_rate, step=mario.curr_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
