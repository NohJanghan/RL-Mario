{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uv 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<url>https://sigridjin.medium.com/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%9D%BC%EB%A9%B4-uv-%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%A9%EC%8B%9C%EB%8B%A4-546d523f7178<url>\n",
    "<br>\n",
    "<url>https://rudaks.tistory.com/entry/python%EC%9D%98-uv-%EC%82%AC%EC%9A%A9%EB%B2%95<url>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# terminal 에서\n",
    "brew install uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# project 생성 : 폴더 생성하니 프로젝트를 만들고 싶은 위치에서 실행\n",
    "uv init <project_name> \n",
    "# 설치가 되면 디렉토리 이동\n",
    "cd <project_name>\n",
    "\n",
    "# venv 생성\n",
    "uv venv <venv_name>\n",
    "# venv 실행\n",
    "source ./venv/<venv_name>/bin/activate\n",
    "# 파이썬 설치\n",
    "uv python install 3.10 or later\n",
    "# 주의!!! ipynb 사용 시에는 반드시 --devfh ipykernel 설치 할 것. 파이썬 버전은 이 라이브러리 버전으로 잡히니, notebook에서 버전 확인이 이상하면 이 패키지 관리\n",
    "uv add --dev ipykernel\n",
    "# 나머지 필요 패키지 설치\n",
    "uv add torch torchvision torchaudio gym-super-mario-bros numpy=1.22.4 pandas matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code\n",
    "%%bash\n",
    "uv add gym-super-mario-bros==7.4.0\n",
    "uv add tensordict==0.3.0\n",
    "uv add torchrl==0.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<url>https://tutorials.pytorch.kr/intermediate/mario_rl_tutorial.html#<url>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import random, datetime, os\n",
    "\n",
    "# Gym은 강화학습을 위한 OpenAI 툴킷입니다.\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "from gym.wrappers import FrameStack\n",
    "\n",
    "# OpenAI Gym을 위한 NES 에뮬레이터\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "# OpenAI Gym에서의 슈퍼 마리오 환경 세팅\n",
    "import gym_super_mario_bros\n",
    "\n",
    "from tensordict import TensorDict\n",
    "from torchrl.data import TensorDictReplayBuffer, LazyMemmapStorage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error uint8~~~\n",
    "<url>https://stackoverflow.com/questions/78757000/overflowerror-when-setting-up-gym-super-mario-bros-environment-in-python-on-jupy<url>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL-env setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bagjuhyeon/RL-game/.venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/bagjuhyeon/RL-game/.venv/lib/python3.10/site-packages/gym/envs/registration.py:627: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'video.frames_per_second']\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 256, 3),\n",
      " 0.0,\n",
      " False,\n",
      " {'coins': 0, 'flag_get': False, 'life': 2, 'score': 0, 'stage': 1, 'status': 'small', 'time': 400, 'world': 1, 'x_pos': 40, 'y_pos': 79}\n"
     ]
    }
   ],
   "source": [
    "# 슈퍼 마리오 환경 초기화하기 (in v0.26 change render mode to 'human' to see results on the screen)\n",
    "# numpy 2.0 version은 uint8에서 crash\n",
    "if gym.__version__ < '0.26':\n",
    "    env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\", new_step_api=True)\n",
    "else:\n",
    "    env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\", render_mode='human', apply_api_compatibility=True)\n",
    "\n",
    "# 상태 공간을 2가지로 제한하기\n",
    "#   0. 오른쪽으로 걷기\n",
    "#   1. 오른쪽으로 점프하기\n",
    "env = JoypadSpace(env, [[\"right\"], [\"right\", \"A\"]])\n",
    "\n",
    "env.reset()\n",
    "next_state, reward, done, trunc, info = env.step(action=0)\n",
    "print(f\"{next_state.shape},\\n {reward},\\n {done},\\n {info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipFrame(gym.Wrapper):\n",
    "    def __init__(self, env, skip):\n",
    "        \"\"\"모든 `skip` 프레임만 반환합니다.\"\"\"\n",
    "        super().__init__(env)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"행동을 반복하고 포상을 더합니다.\"\"\"\n",
    "        total_reward = 0.0\n",
    "        for i in range(self._skip):\n",
    "            # 포상을 누적하고 동일한 작업을 반복합니다.\n",
    "            obs, reward, done, trunk, info = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, done, trunk, info\n",
    "\n",
    "\n",
    "class GrayScaleObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        obs_shape = self.observation_space.shape[:2]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def permute_orientation(self, observation):\n",
    "        # [H, W, C] 배열을 [C, H, W] 텐서로 바꿉니다.\n",
    "        observation = np.transpose(observation, (2, 0, 1))\n",
    "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
    "        return observation\n",
    "\n",
    "    def observation(self, observation):\n",
    "        observation = self.permute_orientation(observation)\n",
    "        transform = T.Grayscale()\n",
    "        observation = transform(observation)\n",
    "        return observation\n",
    "\n",
    "\n",
    "class ResizeObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env, shape):\n",
    "        super().__init__(env)\n",
    "        if isinstance(shape, int):\n",
    "            self.shape = (shape, shape)\n",
    "        else:\n",
    "            self.shape = tuple(shape)\n",
    "\n",
    "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        transforms = T.Compose(\n",
    "            [T.Resize(self.shape, antialias=True), T.Normalize(0, 255)]\n",
    "        )\n",
    "        observation = transforms(observation).squeeze(0)\n",
    "        return observation\n",
    "\n",
    "\n",
    "# 래퍼를 환경에 적용합니다.\n",
    "env = SkipFrame(env, skip=4)\n",
    "env = GrayScaleObservation(env)\n",
    "env = ResizeObservation(env, shape=84)\n",
    "if gym.__version__ < '0.26':\n",
    "    env = FrameStack(env, num_stack=4, new_step_api=True)\n",
    "else:\n",
    "    env = FrameStack(env, num_stack=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Env - Mario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario:\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "        # 마리오의 DNN은 최적의 행동을 예측합니다 - 이는 학습하기 섹션에서 구현합니다.\n",
    "        self.net = MarioNet(self.state_dim, self.action_dim).float()\n",
    "        self.net = self.net.to(device=self.device)\n",
    "\n",
    "        self.exploration_rate = 1\n",
    "        self.exploration_rate_decay = 0.99999975\n",
    "        self.exploration_rate_min = 0.1\n",
    "        self.curr_step = 0\n",
    "\n",
    "        self.save_every = 5e5  # Mario Net 저장 사이의 경험 횟수\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"\n",
    "    주어진 상태에서, 입실론-그리디 행동(epsilon-greedy action)을 선택하고, 스텝의 값을 업데이트 합니다.\n",
    "\n",
    "    입력값:\n",
    "    state (``LazyFrame``): 현재 상태에서의 단일 상태(observation)값을 말합니다. 차원은 (state_dim)입니다.\n",
    "    출력값:\n",
    "    ``action_idx`` (int): Mario가 수행할 행동을 나타내는 정수 값입니다.\n",
    "    \"\"\"\n",
    "        # 임의의 행동을 선택하기\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            action_idx = np.random.randint(self.action_dim)\n",
    "\n",
    "        # 최적의 행동을 이용하기\n",
    "        else:\n",
    "            state = state[0].__array__() if isinstance(state, tuple) else state.__array__()\n",
    "            state = torch.tensor(state, device=self.device).unsqueeze(0)\n",
    "            action_values = self.net(state, model=\"online\")\n",
    "            action_idx = torch.argmax(action_values, axis=1).item()\n",
    "\n",
    "        # exploration_rate 감소하기\n",
    "        self.exploration_rate *= self.exploration_rate_decay\n",
    "        self.exploration_rate = max(self.exploration_rate_min, self.exploration_rate)\n",
    "\n",
    "        # 스텝 수 증가하기\n",
    "        self.curr_step += 1\n",
    "        return action_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):  # 연속성을 위한 하위 클래스입니다.\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.memory = TensorDictReplayBuffer(storage=LazyMemmapStorage(100000, device=torch.device(\"cpu\")))\n",
    "        self.batch_size = 32\n",
    "\n",
    "    def cache(self, state, next_state, action, reward, done):\n",
    "        \"\"\"\n",
    "        Store the experience to self.memory (replay buffer)\n",
    "\n",
    "        입력값:\n",
    "        state (``LazyFrame``),\n",
    "        next_state (``LazyFrame``),\n",
    "        action (``int``),\n",
    "        reward (``float``),\n",
    "        done(``bool``))\n",
    "        \"\"\"\n",
    "        def first_if_tuple(x):\n",
    "            return x[0] if isinstance(x, tuple) else x\n",
    "        state = first_if_tuple(state).__array__()\n",
    "        next_state = first_if_tuple(next_state).__array__()\n",
    "\n",
    "        state = torch.tensor(state)\n",
    "        next_state = torch.tensor(next_state)\n",
    "        action = torch.tensor([action])\n",
    "        reward = torch.tensor([reward])\n",
    "        done = torch.tensor([done])\n",
    "\n",
    "        # self.memory.append((state, next_state, action, reward, done,))\n",
    "        self.memory.add(TensorDict({\"state\": state, \"next_state\": next_state, \"action\": action, \"reward\": reward, \"done\": done}, batch_size=[]))\n",
    "\n",
    "    def recall(self):\n",
    "        \"\"\"\n",
    "        메모리에서 일련의 경험들을 검색합니다.\n",
    "        \"\"\"\n",
    "        batch = self.memory.sample(self.batch_size).to(self.device)\n",
    "        state, next_state, action, reward, done = (batch.get(key) for key in (\"state\", \"next_state\", \"action\", \"reward\", \"done\"))\n",
    "        return state, next_state, action.squeeze(), reward.squeeze(), done.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MarioNet(CNN model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.gamma = 0.9\n",
    "\n",
    "    def td_estimate(self, state, action):\n",
    "        current_Q = self.net(state, model=\"online\")[\n",
    "            np.arange(0, self.batch_size), action\n",
    "        ]  # Q_online(s,a)\n",
    "        return current_Q\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def td_target(self, reward, next_state, done):\n",
    "        next_state_Q = self.net(next_state, model=\"online\")\n",
    "        best_action = torch.argmax(next_state_Q, axis=1)\n",
    "        next_Q = self.net(next_state, model=\"target\")[\n",
    "            np.arange(0, self.batch_size), best_action\n",
    "        ]\n",
    "        return (reward + (1 - done.float()) * self.gamma * next_Q).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=0.00025)\n",
    "        self.loss_fn = torch.nn.SmoothL1Loss()\n",
    "\n",
    "    def update_Q_online(self, td_estimate, td_target):\n",
    "        loss = self.loss_fn(td_estimate, td_target)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def sync_Q_target(self):\n",
    "        self.net.target.load_state_dict(self.net.online.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def save(self):\n",
    "        save_path = (\n",
    "            self.save_dir / f\"mario_net_{int(self.curr_step // self.save_every)}.chkpt\"\n",
    "        )\n",
    "        torch.save(\n",
    "            dict(model=self.net.state_dict(), exploration_rate=self.exploration_rate),\n",
    "            save_path,\n",
    "        )\n",
    "        print(f\"MarioNet saved to {save_path} at step {self.curr_step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.burnin = 1e4  # 학습을 진행하기 전 최소한의 경험값.\n",
    "        self.learn_every = 3  # Q_online 업데이트 사이의 경험 횟수.\n",
    "        self.sync_every = 1e4  # Q_target과 Q_online sync 사이의 경험 수\n",
    "\n",
    "    def learn(self):\n",
    "        if self.curr_step % self.sync_every == 0:\n",
    "            self.sync_Q_target()\n",
    "\n",
    "        if self.curr_step % self.save_every == 0:\n",
    "            self.save()\n",
    "\n",
    "        if self.curr_step < self.burnin:\n",
    "            return None, None\n",
    "\n",
    "        if self.curr_step % self.learn_every != 0:\n",
    "            return None, None\n",
    "\n",
    "        # 메모리로부터 샘플링을 합니다.\n",
    "        state, next_state, action, reward, done = self.recall()\n",
    "\n",
    "        # TD 추정값을 가져옵니다.\n",
    "        td_est = self.td_estimate(state, action)\n",
    "\n",
    "        # TD 목표값을 가져옵니다.\n",
    "        td_tgt = self.td_target(reward, next_state, done)\n",
    "\n",
    "        # 실시간 Q(Q_online)을 통해 역전파 손실을 계산합니다.\n",
    "        loss = self.update_Q_online(td_est, td_tgt)\n",
    "\n",
    "        return (td_est.mean().item(), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logger -> perception of agent behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MetricLogger:\n",
    "    def __init__(self, save_dir):\n",
    "        self.save_log = save_dir / \"log\"\n",
    "        with open(self.save_log, \"w\") as f:\n",
    "            f.write(\n",
    "                f\"{'Episode':>8}{'Step':>8}{'Epsilon':>10}{'MeanReward':>15}\"\n",
    "                f\"{'MeanLength':>15}{'MeanLoss':>15}{'MeanQValue':>15}\"\n",
    "                f\"{'TimeDelta':>15}{'Time':>20}\\n\"\n",
    "            )\n",
    "        self.ep_rewards_plot = save_dir / \"reward_plot.jpg\"\n",
    "        self.ep_lengths_plot = save_dir / \"length_plot.jpg\"\n",
    "        self.ep_avg_losses_plot = save_dir / \"loss_plot.jpg\"\n",
    "        self.ep_avg_qs_plot = save_dir / \"q_plot.jpg\"\n",
    "\n",
    "        # 지표(Metric)와 관련된 리스트입니다.\n",
    "        self.ep_rewards = []\n",
    "        self.ep_lengths = []\n",
    "        self.ep_avg_losses = []\n",
    "        self.ep_avg_qs = []\n",
    "\n",
    "        # 모든 record() 함수를 호출한 후 이동 평균(Moving average)을 계산합니다.\n",
    "        self.moving_avg_ep_rewards = []\n",
    "        self.moving_avg_ep_lengths = []\n",
    "        self.moving_avg_ep_avg_losses = []\n",
    "        self.moving_avg_ep_avg_qs = []\n",
    "\n",
    "        # 현재 에피스드에 대한 지표를 기록합니다.\n",
    "        self.init_episode()\n",
    "\n",
    "        # 시간에 대한 기록입니다.\n",
    "        self.record_time = time.time()\n",
    "\n",
    "    def log_step(self, reward, loss, q):\n",
    "        self.curr_ep_reward += reward\n",
    "        self.curr_ep_length += 1\n",
    "        if loss:\n",
    "            self.curr_ep_loss += loss\n",
    "            self.curr_ep_q += q\n",
    "            self.curr_ep_loss_length += 1\n",
    "\n",
    "    def log_episode(self):\n",
    "        \"에피스드의 끝을 표시합니다.\"\n",
    "        self.ep_rewards.append(self.curr_ep_reward)\n",
    "        self.ep_lengths.append(self.curr_ep_length)\n",
    "        if self.curr_ep_loss_length == 0:\n",
    "            ep_avg_loss = 0\n",
    "            ep_avg_q = 0\n",
    "        else:\n",
    "            ep_avg_loss = np.round(self.curr_ep_loss / self.curr_ep_loss_length, 5)\n",
    "            ep_avg_q = np.round(self.curr_ep_q / self.curr_ep_loss_length, 5)\n",
    "        self.ep_avg_losses.append(ep_avg_loss)\n",
    "        self.ep_avg_qs.append(ep_avg_q)\n",
    "\n",
    "        self.init_episode()\n",
    "\n",
    "    def init_episode(self):\n",
    "        self.curr_ep_reward = 0.0\n",
    "        self.curr_ep_length = 0\n",
    "        self.curr_ep_loss = 0.0\n",
    "        self.curr_ep_q = 0.0\n",
    "        self.curr_ep_loss_length = 0\n",
    "\n",
    "    def record(self, episode, epsilon, step):\n",
    "        mean_ep_reward = np.round(np.mean(self.ep_rewards[-100:]), 3)\n",
    "        mean_ep_length = np.round(np.mean(self.ep_lengths[-100:]), 3)\n",
    "        mean_ep_loss = np.round(np.mean(self.ep_avg_losses[-100:]), 3)\n",
    "        mean_ep_q = np.round(np.mean(self.ep_avg_qs[-100:]), 3)\n",
    "        self.moving_avg_ep_rewards.append(mean_ep_reward)\n",
    "        self.moving_avg_ep_lengths.append(mean_ep_length)\n",
    "        self.moving_avg_ep_avg_losses.append(mean_ep_loss)\n",
    "        self.moving_avg_ep_avg_qs.append(mean_ep_q)\n",
    "\n",
    "        last_record_time = self.record_time\n",
    "        self.record_time = time.time()\n",
    "        time_since_last_record = np.round(self.record_time - last_record_time, 3)\n",
    "\n",
    "        print(\n",
    "            f\"Episode {episode} - \"\n",
    "            f\"Step {step} - \"\n",
    "            f\"Epsilon {epsilon} - \"\n",
    "            f\"Mean Reward {mean_ep_reward} - \"\n",
    "            f\"Mean Length {mean_ep_length} - \"\n",
    "            f\"Mean Loss {mean_ep_loss} - \"\n",
    "            f\"Mean Q Value {mean_ep_q} - \"\n",
    "            f\"Time Delta {time_since_last_record} - \"\n",
    "            f\"Time {datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\"\n",
    "        )\n",
    "\n",
    "        with open(self.save_log, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"{episode:8d}{step:8d}{epsilon:10.3f}\"\n",
    "                f\"{mean_ep_reward:15.3f}{mean_ep_length:15.3f}{mean_ep_loss:15.3f}{mean_ep_q:15.3f}\"\n",
    "                f\"{time_since_last_record:15.3f}\"\n",
    "                f\"{datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S'):>20}\\n\"\n",
    "            )\n",
    "\n",
    "        for metric in [\"ep_lengths\", \"ep_avg_losses\", \"ep_avg_qs\", \"ep_rewards\"]:\n",
    "            plt.clf()\n",
    "            plt.plot(getattr(self, f\"moving_avg_{metric}\"), label=f\"moving_avg_{metric}\")\n",
    "            plt.legend()\n",
    "            plt.savefig(getattr(self, f\"{metric}_plot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mps.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n",
      "Using MPS: True\n",
      "Episode 0 - Step 423 - Epsilon 0.9998942555781016 - Mean Reward 998.0 - Mean Length 423.0 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 7.11 - Time 2025-05-07T20:03:05\n",
      "Episode 20 - Step 3418 - Epsilon 0.9991458648743183 - Mean Reward 575.714 - Mean Length 162.762 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 48.611 - Time 2025-05-07T20:03:53\n",
      "Episode 39 - Step 7103 - Epsilon 0.9982258254893794 - Mean Reward 573.575 - Mean Length 177.575 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 59.864 - Time 2025-05-07T20:04:53\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "print(f\"Using CUDA: {use_cuda}\")\n",
    "print(f\"Using MPS: {use_mps}\")\n",
    "\n",
    "save_dir = Path(\"checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "save_dir.mkdir(parents=True)\n",
    "\n",
    "mario = Mario(state_dim=(4, 84, 84), action_dim=env.action_space.n, save_dir=save_dir)\n",
    "\n",
    "logger = MetricLogger(save_dir)\n",
    "\n",
    "episodes = 40\n",
    "for e in range(episodes):\n",
    "\n",
    "    state = env.reset()\n",
    "\n",
    "    # 게임을 실행시켜봅시다!\n",
    "    while True:\n",
    "\n",
    "        # 현재 상태에서 에이전트 실행하기\n",
    "        action = mario.act(state)\n",
    "\n",
    "        # 에이전트가 액션 수행하기\n",
    "        next_state, reward, done, trunc, info = env.step(action)\n",
    "\n",
    "        # 기억하기\n",
    "        mario.cache(state, next_state, action, reward, done)\n",
    "\n",
    "        # 배우기\n",
    "        q, loss = mario.learn()\n",
    "\n",
    "        # 기록하기\n",
    "        logger.log_step(reward, loss, q)\n",
    "\n",
    "        # 상태 업데이트하기\n",
    "        state = next_state\n",
    "\n",
    "        # 게임이 끝났는지 확인하기\n",
    "        if done or info[\"flag_get\"]:\n",
    "            break\n",
    "\n",
    "    logger.log_episode()\n",
    "\n",
    "    if (e % 20 == 0) or (e == episodes - 1):\n",
    "        logger.record(episode=e, epsilon=mario.exploration_rate, step=mario.curr_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
